---
phase: 01-media-scanner
plan: 04
type: execute
wave: 3
depends_on: ["01-02", "01-03"]
files_modified:
  - src/scanner.ts
  - src/output/json.ts
  - src/output/csv.ts
autonomous: true

must_haves:
  truths:
    - "Scanner recursively finds all image and video files in specified directories"
    - "Scanner processes files concurrently with configurable limit"
    - "Scanner filters for 16:9 content and collects matches"
    - "Scanner detects duplicates when option enabled"
    - "JSON output contains all match data with metadata"
    - "CSV output contains all match data in tabular format"
  artifacts:
    - path: "src/scanner.ts"
      provides: "Main scanner orchestration"
      exports: ["scanDirectories"]
    - path: "src/output/json.ts"
      provides: "JSON output formatter"
      exports: ["formatJson", "writeJson"]
    - path: "src/output/csv.ts"
      provides: "CSV output formatter"
      exports: ["formatCsv", "writeCsv"]
  key_links:
    - from: "src/scanner.ts"
      to: "src/readers/image.ts"
      via: "import"
      pattern: "readImage"
    - from: "src/scanner.ts"
      to: "src/readers/video.ts"
      via: "import"
      pattern: "readVideo"
    - from: "src/scanner.ts"
      to: "src/filters/duplicate.ts"
      via: "import"
      pattern: "findDuplicates"
---

<objective>
Implement the scanner orchestration and output formatters that tie everything together.

Purpose: Create the core scanner that traverses directories, processes files through readers and filters, and outputs results in JSON or CSV format.
Output: Scanner module that coordinates all components, plus JSON and CSV output modules.
</objective>

<execution_context>
@/Users/jamessink/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jamessink/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-media-scanner/01-RESEARCH.md
@.planning/phases/01-media-scanner/01-02-SUMMARY.md
@.planning/phases/01-media-scanner/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create scanner orchestration module</name>
  <files>src/scanner.ts</files>
  <action>
Create src/scanner.ts that coordinates directory traversal, readers, and filters:

```typescript
import { readdir, stat } from 'node:fs/promises';
import { join, extname } from 'node:path';
import { readImage } from './readers/image.js';
import { readVideo } from './readers/video.js';
import { findDuplicates, hashFile, markDuplicates } from './filters/duplicate.js';
import {
  MediaInfo, ScanResult, SkippedFile, ScanStats, ScanOptions,
  IMAGE_EXTENSIONS, VIDEO_EXTENSIONS, SUPPORTED_EXTENSIONS
} from './types.js';

export interface ScanCallbacks {
  onFileFound?: (count: number) => void;
  onFileProcessed?: (current: number, total: number, file: string) => void;
  onHashProgress?: (current: number, total: number) => void;
}

/**
 * Scan directories for 16:9 media files
 */
export async function scanDirectories(
  directories: string[],
  options: ScanOptions,
  callbacks?: ScanCallbacks
): Promise<ScanResult> {
  const startTime = Date.now();
  const matches: MediaInfo[] = [];
  const skipped: SkippedFile[] = [];
  let imagesProcessed = 0;
  let videosProcessed = 0;

  // Phase 1: Collect all supported files
  const allFiles: string[] = [];
  for (const dir of directories) {
    const files = await collectFiles(dir);
    allFiles.push(...files);
    callbacks?.onFileFound?.(allFiles.length);
  }

  // Phase 2: Process files (with concurrency limit)
  const concurrency = options.concurrency || 25;
  for (let i = 0; i < allFiles.length; i += concurrency) {
    const batch = allFiles.slice(i, i + concurrency);
    const results = await Promise.all(
      batch.map(async (file) => {
        const ext = extname(file).toLowerCase();
        let result: MediaInfo | null = null;

        try {
          if (IMAGE_EXTENSIONS.includes(ext)) {
            result = await readImage(file);
            if (result) imagesProcessed++;
          } else if (VIDEO_EXTENSIONS.includes(ext)) {
            result = await readVideo(file);
            if (result) videosProcessed++;
          }
        } catch (error) {
          skipped.push({ path: file, reason: (error as Error).message });
        }

        return result;
      })
    );

    // Collect 16:9 matches
    for (const result of results) {
      if (result?.is16by9) {
        matches.push(result);
      }
    }

    callbacks?.onFileProcessed?.(Math.min(i + concurrency, allFiles.length), allFiles.length, batch[0]);
  }

  // Phase 3: Duplicate detection (if enabled)
  let duplicates: DuplicateGroup[] = [];
  if (options.duplicates !== false && matches.length > 0) {
    // Hash all matches
    for (let i = 0; i < matches.length; i++) {
      try {
        matches[i].hash = await hashFile(matches[i].path);
      } catch (error) {
        // If can't hash, continue without it
      }
      callbacks?.onHashProgress?.(i + 1, matches.length);
    }

    // Find duplicate groups
    const matchPaths = matches.map(m => m.path);
    duplicates = await findDuplicates(matchPaths);
    markDuplicates(matches, duplicates);
  }

  const stats: ScanStats = {
    totalFiles: allFiles.length,
    imagesProcessed,
    videosProcessed,
    matchCount: matches.length,
    duplicateCount: duplicates.reduce((sum, g) => sum + g.count - 1, 0), // -1 because original isn't a dup
    skippedCount: skipped.length,
    scanDuration: Date.now() - startTime
  };

  return { matches, skipped, duplicates, stats };
}

/**
 * Recursively collect all supported files from a directory
 */
async function collectFiles(directory: string): Promise<string[]> {
  const files: string[] = [];

  try {
    const entries = await readdir(directory, { withFileTypes: true, recursive: true });

    for (const entry of entries) {
      if (entry.isFile()) {
        const ext = extname(entry.name).toLowerCase();
        if (SUPPORTED_EXTENSIONS.includes(ext)) {
          // Node 20+: entry.parentPath contains full path
          const fullPath = entry.parentPath
            ? join(entry.parentPath, entry.name)
            : join(directory, entry.name);
          files.push(fullPath);
        }
      }
    }
  } catch (error) {
    console.warn(`Could not read directory ${directory}: ${(error as Error).message}`);
  }

  return files;
}
```

Key implementation details:
- Use native fs.promises.readdir with recursive: true (RESEARCH.md pattern)
- Process files in batches with configurable concurrency (default 25)
- Callbacks for progress reporting (used by CLI)
- Skip files that fail processing (don't crash)
- Only hash matches (not all files) for efficiency
- Mark duplicates on MediaInfo objects for output
  </action>
  <verify>
Compile with `npx tsc --noEmit`
Integration test will be done in Plan 05 with CLI
  </verify>
  <done>src/scanner.ts orchestrates directory traversal, file processing, and duplicate detection</done>
</task>

<task type="auto">
  <name>Task 2: Create JSON and CSV output formatters</name>
  <files>src/output/json.ts, src/output/csv.ts</files>
  <action>
Create src/output/json.ts:

```typescript
import { writeFile } from 'node:fs/promises';
import { ScanResult, MediaInfo } from '../types.js';

/**
 * Format scan results as JSON string
 */
export function formatJson(result: ScanResult): string {
  return JSON.stringify(result, null, 2);
}

/**
 * Write scan results to JSON file
 */
export async function writeJson(result: ScanResult, filePath: string): Promise<void> {
  await writeFile(filePath, formatJson(result), 'utf-8');
}

/**
 * Format just the matches (for piping to other tools)
 */
export function formatMatchesJson(matches: MediaInfo[]): string {
  return JSON.stringify(matches, null, 2);
}
```

Create src/output/csv.ts:

```typescript
import { writeFile } from 'node:fs/promises';
import { ScanResult, MediaInfo } from '../types.js';

const CSV_HEADERS = [
  'path',
  'type',
  'width',
  'height',
  'aspectRatio',
  'format',
  'size',
  'isDuplicate',
  'duplicateOf'
];

/**
 * Escape a CSV field value
 */
function escapeField(value: string | number | boolean | undefined): string {
  if (value === undefined || value === null) return '';
  const str = String(value);
  // Escape quotes and wrap in quotes if contains comma, quote, or newline
  if (str.includes(',') || str.includes('"') || str.includes('\n')) {
    return `"${str.replace(/"/g, '""')}"`;
  }
  return str;
}

/**
 * Convert MediaInfo to CSV row
 */
function mediaInfoToRow(info: MediaInfo): string {
  return [
    escapeField(info.path),
    escapeField(info.type),
    escapeField(info.width),
    escapeField(info.height),
    escapeField(info.aspectRatio.toFixed(4)),
    escapeField(info.format),
    escapeField(info.size),
    escapeField(info.isDuplicate ?? false),
    escapeField(info.duplicateOf ?? '')
  ].join(',');
}

/**
 * Format scan results as CSV string
 */
export function formatCsv(result: ScanResult): string {
  const lines = [CSV_HEADERS.join(',')];
  for (const match of result.matches) {
    lines.push(mediaInfoToRow(match));
  }
  return lines.join('\n');
}

/**
 * Write scan results to CSV file
 */
export async function writeCsv(result: ScanResult, filePath: string): Promise<void> {
  await writeFile(filePath, formatCsv(result), 'utf-8');
}
```

Key implementation details:
- JSON includes full ScanResult (matches, skipped, duplicates, stats)
- CSV includes match data with duplicate flags
- Proper CSV escaping for fields containing commas, quotes, newlines
- Helper functions for formatting only (returning strings) vs writing files
  </action>
  <verify>
Compile with `npx tsc --noEmit`
Test formatCsv escaping:
- Path with comma should be quoted
- Path with quote should have doubled quotes
  </verify>
  <done>src/output/json.ts and src/output/csv.ts provide formatted output for scan results</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes
2. Scanner imports and uses all reader and filter modules
3. Scanner processes files in batches with concurrency control
4. Scanner skips unreadable files without crashing
5. JSON output includes matches, skipped, duplicates, stats
6. CSV output has proper headers and escaped values
</verification>

<success_criteria>
- Scanner recursively collects supported files from directories
- Scanner processes images and videos through respective readers
- Scanner filters for 16:9 content only
- Scanner detects duplicates via hash when enabled
- JSON output is valid JSON with full scan result
- CSV output has headers and properly escaped values
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-media-scanner/01-04-SUMMARY.md`
</output>
